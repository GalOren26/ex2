{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ex2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTe7RFUzScFv",
        "outputId": "c50e1212-232c-496d-b9cc-dda698d1a4a6"
      },
      "source": [
        "%cd / \n",
        "! git clone https://github.com/galoren287199/ex2.git\n",
        "%cd ex2\n",
        "%ls\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n",
            "Cloning into 'ex2'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 31 (delta 10), reused 13 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (31/31), done.\n",
            "/ex2\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  ex2.ipynb  lm.py  ptb-lm.py  reader.py  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC_0gomLSe4D"
      },
      "source": [
        "\n",
        "import collections\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "def read_words(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.read().replace(\"\\n\", \"<eos>\").split()\n",
        "\n",
        "\n",
        "def build_vocab(filename):\n",
        "  data = read_words(filename)\n",
        "  words=set(data)\n",
        "  word_to_id = dict(zip(words, range(len(words))))\n",
        "  id_to_word = dict((v, k) for k, v in word_to_id.items())\n",
        "  return word_to_id, id_to_word\n",
        "\n",
        "\n",
        "def file_to_word_ids(filename, word_to_id):\n",
        "  data = read_words(filename)\n",
        "  return [word_to_id[word] for word in data if word in word_to_id]\n",
        "\n",
        "\n",
        "def files_raw_data(paths,names,word_to_id,trainRatio=1):\n",
        "    data={}\n",
        "    for idx,path in enumerate(paths):\n",
        "        data[names[idx]]=file_to_word_ids(path,word_to_id)\n",
        "    if trainRatio!=1: \n",
        "        data['train']=RandomSampleAcordionRatio(data['train'],trainRatio)\n",
        "    return data     \n",
        "def RandomSampleAcordionRatio(data,ratio):\n",
        "     start_idx=int(np.random.uniform(0,1-ratio)*len(data))\n",
        "     end_idx=start_idx+int(ratio*len(data))\n",
        "     return data[start_idx:end_idx]\n",
        "def full_path_files(base,names_of_files):\n",
        "    return [base+name for name in names_of_files]\n",
        "\n",
        "def ptb_iterator(raw_data, batch_size, num_steps):\n",
        "       \n",
        "  \"\"\"Iterate on the raw PTB data.\n",
        "  This generates batch_size pointers into the raw PTB data, and allows\n",
        "  minibatch iteration along these pointers. \n",
        "  \n",
        "  make the raw data iterater in dim  [batch_size,seq_len] when all the data store at \n",
        "  [batch_size,batch_len]-> batch_len*batch*size=len(data)\n",
        "  \n",
        "  Args:\n",
        "    raw_data: one of the raw data outputs from ptb_raw_data.\n",
        "    batch_size: int, the batch size.\n",
        "    num_steps: int, the number of unrolls.\n",
        "  Yields:\n",
        "    Pairs of the batched data, each a matrix of shape [batch_size, num_steps].\n",
        "    The second element of the tuple is the same data time-shifted to the\n",
        "    right by one.\n",
        "  Raises:\n",
        "    ValueError: if batch_size or num_steps are too high.\n",
        "  \"\"\"\n",
        "  \n",
        "  raw_data = np.array(raw_data, dtype=np.int32)\n",
        "  data_len = len(raw_data)\n",
        "  batch_len = data_len // batch_size\n",
        "  data = np.zeros([batch_size, batch_len], dtype=np.int32)\n",
        "  for i in range(batch_size):\n",
        "    data[i] = raw_data[batch_len * i:batch_len * (i + 1)]\n",
        "\n",
        "\n",
        "  epoch_size = (batch_len - 1) // num_steps\n",
        "\n",
        "  if epoch_size == 0:\n",
        "    raise ValueError(\"epoch_size == 0, decrease batch_size or num_steps\")\n",
        "\n",
        "  for i in range(epoch_size):\n",
        "    x = data[:, i*num_steps:(i+1)*num_steps]\n",
        "    y = data[:, i*num_steps+1:(i+1)*num_steps+1]\n",
        "    yield (x, y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFoiBFQySggp"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.tensor as tensor \n",
        "class Rnn(nn.Module):\n",
        "  \"\"\"Simple LSMT-based language model\"\"\"\n",
        "  \n",
        "  #to change embbeding dim \n",
        "  #to change drop out  val \n",
        "   # change init_hidden \n",
        "   # check the lerning rate\n",
        "   #change  dp_keep_prob\n",
        "   \n",
        "   # consider of we need clip_grad_norm\n",
        "   #consider using step insted \n",
        "   \n",
        "   #CHECK FOR PREPLXTIY CALC \n",
        "   \n",
        "  def __init__(self,net,embedding_dim, seq_len, batch_size, vocab_size, num_layers, dp_keep_prob,lr=1,lr_decay_base=2,ephocs_witout_decay=4):\n",
        "    super(Rnn, self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.seq_len = seq_len\n",
        "    self.batch_size = batch_size\n",
        "    self.vocab_size = vocab_size\n",
        "    self.dp_keep_prob = dp_keep_prob\n",
        "    self.num_layers = num_layers\n",
        "    self.dropout = nn.Dropout(1 - dp_keep_prob)\n",
        "    self.net_name=net\n",
        "    self.first_lr=lr\n",
        "    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "    if net==\"lstm\":\n",
        "        self.net = nn.LSTM(input_size=embedding_dim,\n",
        "                                hidden_size=embedding_dim,\n",
        "                                num_layers=num_layers,\n",
        "                                dropout=1 - dp_keep_prob)\n",
        "    \n",
        "    else:\n",
        "        self.net =nn.GRU(input_size=embedding_dim,\n",
        "                                hidden_size=embedding_dim,\n",
        "                                num_layers=num_layers,\n",
        "                                dropout=1 - dp_keep_prob)\n",
        "    self.sm_fc = nn.Linear(in_features=embedding_dim,\n",
        "                           out_features=vocab_size)\n",
        "    self.lr=lr\n",
        "    self.ephocs_witout_decay=ephocs_witout_decay\n",
        "    self.lr_decay_base=lr_decay_base\n",
        "    self.init_weights()\n",
        "    self.train_perplexity=[]\n",
        "    self.test_perplexity=[]\n",
        "    self.already_decayed=False\n",
        "  def init_weights(self):\n",
        "    init_range = 0.1\n",
        "    nn.init.xavier_normal_(self.word_embeddings.weight.data)\n",
        "    # self.word_embeddings.weight.data.uniform_(-init_range, init_range)\n",
        "    self.sm_fc.bias.data.fill_(0.0)\n",
        "    nn.init.xavier_normal_(self.sm_fc.weight.data)\n",
        "    \n",
        "    # self.sm_fc.weight.data.uniform_(-init_range, init_range)\n",
        "\n",
        "  def init_hidden(self):\n",
        "    weight = next(self.parameters()).data\n",
        "    if self.net_name==\"lstm\":\n",
        "        return (Variable(weight.new(self.num_layers, self.batch_size, self.embedding_dim).zero_()),\n",
        "            Variable(weight.new(self.num_layers, self.batch_size, self.embedding_dim).zero_()))\n",
        "    else :\n",
        "        return   Variable(weight.new(self.num_layers, self.batch_size, self.embedding_dim).zero_())\n",
        "\n",
        "  def forward(self, inputs, hidden):\n",
        "    if self.dp_keep_prob==1:\n",
        "      embeds=self.word_embeddings(inputs)\n",
        "    else : \n",
        "      embeds = self.dropout(self.word_embeddings(inputs))\n",
        "    net_out, hidden = self.net(embeds, hidden)\n",
        "    if self.dp_keep_prob!=1:\n",
        "       net_out = self.dropout(net_out)\n",
        "    logits = self.sm_fc(net_out.view(-1, self.embedding_dim))\n",
        "    return logits.view(self.seq_len, self.batch_size, self.vocab_size), hidden\n",
        "\n",
        "def repackage_hidden(h):\n",
        "  \"\"\"Wraps hidden states in new Variables, to detach them from their history.\"\"\"\n",
        "  if type(h) is  not tuple:\n",
        "    return Variable(h.data)\n",
        "  # else:\n",
        "  #  return tuple(repackage_hidden(v) for v in h)\n",
        "  else:\n",
        "      temp=[]\n",
        "      for i in h:\n",
        "          temp.append(Variable(i.data))\n",
        "      return tuple(temp)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ns3YtcB7SjjD",
        "outputId": "da269637-b7ee-4c37-86bf-3301b28b3aad"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.tensor as tensor \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "\n",
        "\n",
        "\n",
        "args={}\n",
        "args_lstm={\"seq_len\":30,\"batch_size\":20,\"inital_lr\":20,\"num_epochs\":15,  \"lr_decay_base\":2,\"ephocs_witout_decay\":4\n",
        "         ,\"trainRatio\":1,\"data\":\"data/\", \"hidden_size\":200 ,\"num_layers\":2, \"dp_keep_prob\":1,  \"net\":\"lstm\", \"load\":\"lstm_model.pt\",\"save\":\"lstm_model.pt\", \"log_path\":\"./log_lstm.txt\" }\n",
        "\n",
        "\n",
        "# args_gru={\"seq_len\":20,\"batch_size\":20,\"inital_lr\":17,\"num_epochs\":18,  \"lr_decay_base\":1.9,\"ephocs_witout_decay\":4\n",
        "#          ,\"trainRatio\":1,\"data\":\"data/\", \"hidden_size\":200 ,\"num_layers\":2, \"dp_keep_prob\":1,  \"net\":\"gru\", \"load\":\"\",\"save\":\"lm_model_lstm.pt\", \"log_path\":\"./log_lstm.txt\" }\n",
        "args_gru={\"seq_len\":30,\"batch_size\":20,\"inital_lr\":20,\"num_epochs\":15,  \"lr_decay_base\":2,\"ephocs_witout_decay\":4\n",
        "    \n",
        "         ,\"trainRatio\":1,\"data\":\"data/\", \"hidden_size\":200 ,\"num_layers\":2, \"dp_keep_prob\":1,  \"net\":\"gru\", \"load\":\"gru_model.pt\",\"save\":\"gru_model.pt\", \"log_path\":\"./log_gru.txt\" }\n",
        "\n",
        "def save_checkpoint(model,save_path, epoch,trained):\n",
        "    torch.save({\n",
        "        'model': model,\n",
        "        'epoch': epoch,\n",
        "        'trained':trained\n",
        "    }, save_path)\n",
        "def load_checkpoint(load_path):\n",
        "    \n",
        "    checkpoint = torch.load(load_path)\n",
        "    model=checkpoint['model']\n",
        "    epoch = checkpoint['epoch']\n",
        "    trained=checkpoint['trained']\n",
        "    if  not trained:\n",
        "        print('continue to train from epoch {}, see log file for history :)\\n'.format(epoch))\n",
        "    else:\n",
        "        print('load model from file! validate on valid data :)\\n')\n",
        "    return model,epoch ,trained\n",
        "\n",
        "    \n",
        "def run_epoch(model, data, is_train=False, lr=1.0):\n",
        "  \"\"\"Runs the model on the given data.\"\"\"\n",
        "  if is_train:\n",
        "    model.train()\n",
        "  else:\n",
        "    model.eval()\n",
        "    \n",
        "  num_of_seq = ((len(data) // model.batch_size) - 1) // model.seq_len\n",
        "  start_time = time.time()\n",
        "  hidden = model.init_hidden()\n",
        "  costs = 0.0\n",
        "  iters = 0\n",
        "  for step, (x, y) in enumerate(ptb_iterator(data, model.batch_size, model.seq_len)):\n",
        "    inputs = Variable(torch.from_numpy(x.astype(np.int64)).transpose(0, 1).contiguous()).to(device)\n",
        "    model.zero_grad()\n",
        "    hidden = repackage_hidden(hidden)\n",
        "    outputs, hidden = model(inputs, hidden)\n",
        "    targets = Variable(torch.from_numpy(y.astype(np.int64)).transpose(0, 1).contiguous()).to(device)\n",
        "    tt = torch.squeeze(targets.view(-1, model.batch_size * model.seq_len))\n",
        "\n",
        "    loss = criterion(outputs.view(-1, model.vocab_size), tt)\n",
        "    costs += loss.item() * model.seq_len\n",
        "    iters += model.seq_len\n",
        "\n",
        "    if is_train:\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
        "      for p in model.parameters():\n",
        "        p.data.add_(-lr, p.grad.data)\n",
        "      # if step % (num_of_seq // 10) == 10:\n",
        "      #   print(\"{} perplexity: {:8.2f} speed: {} wps\".format(step * 1.0 / num_of_seq, np.exp(costs / iters),\n",
        "      #                                                  iters * model.batch_size / (time.time() - start_time)))\n",
        "  return np.exp(costs / iters)    \n",
        "\n",
        "\n",
        "def train(model=None,epoch=None):\n",
        "    #load model or create it     \n",
        "    if model!=None:\n",
        "        model,epoch_start=model,epoch\n",
        "    else:      \n",
        "        epoch_start=0\n",
        "        model = Rnn(net=args[\"net\"],embedding_dim=200,seq_len=args[\"seq_len\"], batch_size=args[\"batch_size\"],\n",
        "                 vocab_size=vocab_size, num_layers=args[\"num_layers\"], dp_keep_prob=args[\"dp_keep_prob\"],lr=args[\"inital_lr\"],lr_decay_base=args[\"lr_decay_base\"],ephocs_witout_decay=args[\"ephocs_witout_decay\"])\n",
        "    epoch_num=args[\"num_epochs\"]\n",
        "     #convert to device \n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    # if load is avilable get lr and num of ephoc else take the defualt. \n",
        "    cur_epoch=0\n",
        "    f = open(args[\"log_path\"], \"a\")\n",
        "    try:\n",
        "        for epoch in range(epoch_start,epoch_num):\n",
        "            cur_epoch=epoch\n",
        "            if ( epoch>=model.ephocs_witout_decay and not  model.already_decayed ):\n",
        "                  if (100*((abs(model.test_perplexity[-1]- model.test_perplexity[-2]))/model.test_perplexity[-1]) )<2 and model.dp_keep_prob!=1: # only if drop out is enabled then enable not to cut lr when the othe condition exist.\n",
        "                    pass\n",
        "                  else:\n",
        "                    model.lr=model.lr/model.lr_decay_base\n",
        "                    model.already_decayed=True# for serealization \n",
        "                    print(\"decay lr by {}\".format(model.lr_decay_base))\n",
        "            #run one epoch\n",
        "            train_perplexity = run_epoch(model, data[\"train\"], True, model.lr)\n",
        "            test_perplexity=run_epoch(model, data[\"test\"])\n",
        "            # collect results \n",
        "            model.train_perplexity.append(train_perplexity)\n",
        "            model.test_perplexity.append(test_perplexity)\n",
        "            model.already_decayed=False\n",
        "            #check for save model \n",
        "            print('Train perplexity at epoch {}: {:8.2f}'.format(epoch, train_perplexity))\n",
        "            print('test perplexity at epoch {}: {:8.2f}'.format(epoch, test_perplexity))\n",
        "            if min(model.test_perplexity)==test_perplexity:\n",
        "                print(\"save model new result :)\\n\")\n",
        "                save_checkpoint(model,args[\"save\"],epoch,True)\n",
        "            #write to logger \n",
        "            f.write('Train perplexity at epoch {}: {:8.2f}\\n'.format(epoch, train_perplexity))\n",
        "            f.write('test perplexity at epoch {}: {:8.2f}\\n\\n'.format(epoch, test_perplexity))\n",
        "        # write best reult        \n",
        "        preplixty_of_train=min(model.train_perplexity)\n",
        "        preplixty_of_test=min(model.test_perplexity)\n",
        "        f.write('train perplexity at best epoch {}'.format(preplixty_of_train))\n",
        "        f.write('test perplexity at best epoch {}'.format(preplixty_of_test))\n",
        "        f.write('test perplexity at last ephoc  {}: {:8.2f}'.format(epoch,test_perplexity))\n",
        "        model.batch_size = 1 # to make sure we process all the data in the test later\n",
        "        return model\n",
        "    except: \n",
        "      #save model if problem is occured/ trigger stop by user->ctrl+c\n",
        "        print(\"problem or stop by user ,saving current model state for continue later! \")\n",
        "        save_checkpoint(model,args[\"save\"],cur_epoch,False)\n",
        "        return False \n",
        "\n",
        "def PlotResult(model):\n",
        "            f1 = plt.figure()\n",
        "            plt.plot(range(len(model.test_perplexity)),model.test_perplexity)\n",
        "            plt.plot(range(len(model.train_perplexity)),model.train_perplexity)   \n",
        "            plt.legend([\"test preplixty\", \"train preplixty\"], loc =\"upper right\")\n",
        "            plt.xlabel(\"Epoch #\")\n",
        "            plt.ylabel(\"preplixty\")\n",
        "            plt.title(\"perplixty of {} with drop out ratio of : {:4.2f} and learning rate of {} with decay of {} from {} epoch \".format(model.net_name,1-model.dp_keep_prob,model.first_lr,model.lr_decay_base,model.ephocs_witout_decay))\n",
        "            plt.show()\n",
        "def UIuser(args):\n",
        "  print(\"Welcome to ex2 ! \\n\\nfollwing is menu to chose the desired settings for model:\\n\")\n",
        "\n",
        "  print(\"press 1 to see dafault settings for all sections\\n\")\n",
        "  print(\"press 2 to chose lstm without dropot\\n\")\n",
        "  print(\"print 3 to chose lstm with dropout\\n\")\n",
        "  print(\"print 4 to chose gru without dropout\\n\")\n",
        "  print(\"print 5 to chose gru with dropot\\n\")\n",
        "  print(\"print anything else for defualt seeting - lstm without droput \")\n",
        "  print(\"Feel free to change the values in args dict  as you wish for custom settings\")\n",
        "  m_input=input()\n",
        "  if m_input==\"1\":\n",
        "    print(\"lstm:\\n\\n{}\\nlstm with drooout: drop_value:\\n\\n{}\\ngru:\\n\\n{}\\ngru with drooput: drop value\\n\\n{}\\n\".format(args_lstm,0.7,args_gru,0.7))\n",
        "    print(\"chose what you wana do next fromm the option 2-5 above\")\n",
        "    m_input=input()\n",
        "\n",
        "  print(\"\\nprint 1 to  new model  or 2 for load from default save\\n\")\n",
        "  input_2=input()  \n",
        "  \n",
        "  if m_input==\"2\":\n",
        "    if input_2==\"1\":\n",
        "      args_lstm['load']=\"\"\n",
        "      args=args_lstm\n",
        "  elif m_input==\"3\":\n",
        "    args_lstm_do= args_lstm.copy()\n",
        "    args_lstm_do[\"dp_keep_prob\"]=0.7\n",
        "    args_lstm_do[\"ephocs_witout_decay\"]=8\n",
        "    args_lstm_do[\"num_epochs\"]=20\n",
        "    if input_2==\"1\":\n",
        "      args_lstm_do['load']=\"\"\n",
        "    else:\n",
        "      args_lstm_do[\"load\"]=\"lstm_model_do.pt\"\n",
        "    args_lstm_do[ \"save\"]=\"lstm_model_do.pt\"\n",
        "    args_lstm_do[\"log_path\"]:\"./log_lstm_do.txt\"\n",
        "    args=args_lstm_do\n",
        "  elif m_input==\"4\":\n",
        "    if input_2==\"1\":\n",
        "      args_gru['load']=\"\"\n",
        "    args=args_gru\n",
        "  elif m_input==\"5\":\n",
        "    args_gru_do=args_gru.copy()\n",
        "    args_gru_do[\"dp_keep_prob\"]=0.7\n",
        "    args_gru_do[\"ephocs_witout_decay\"]=4\n",
        "    args_gru_do[\"num_epochs\"]=20\n",
        "    if input_2==\"1\":\n",
        "      args_lstm_do['load']=\"\"\n",
        "    else:\n",
        "      args_gru_do[\"load\"]=\"gru_model_do.pt\"\n",
        "    args_gru_do[ \"save\"]=\"gru_model_do.pt\"\n",
        "    args_gru_do[\"log_path\"]:\"./log_gru_do.txt\"\n",
        "    args=args_gru_do\n",
        "  else:\n",
        "    args=args_lstm\n",
        "  return args \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args=UIuser(args)\n",
        "    print(args)\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #open log file results \n",
        "    if path.exists(args[\"load\"]):\n",
        "      mode='a'\n",
        "    else:\n",
        "      mode='w'\n",
        "    f = open(args[\"log_path\"],mode)\n",
        "    f.write(\"hello from training\\n\")\n",
        "    f.close()\n",
        "    ## --read data and parse to voacb \n",
        "    paths=[\"ptb.train.txt\",\"ptb.valid.txt\",\"ptb.test.txt\"]\n",
        "    names_of_files=[\"train\",\"valid\",\"test\"]\n",
        "    paths = full_path_files(args[\"data\"],paths)\n",
        "    train_name=paths[0]\n",
        "    word_to_id, id_2_word =build_vocab(train_name)\n",
        "    # return for each file list of the words in the file encoded to id by the word to id dict \n",
        "    data=files_raw_data(paths,names_of_files,word_to_id,args[\"trainRatio\"])\n",
        "    vocab_size = len(word_to_id)\n",
        "    criterion = nn.CrossEntropyLoss()  \n",
        "\n",
        "\n",
        "    print (\"------- training ------\\n\")\n",
        "    if path.exists(args['load']):\n",
        "        model,epoch,trained=load_checkpoint(args['load'])\n",
        "        if not trained:\n",
        "           model=train(model,epoch)\n",
        "    else :\n",
        "       model=train() \n",
        "        \n",
        "    print (\"---- end training ------\\n\")\n",
        "    if model:\n",
        "        model.batch_size = 1 # to make sure we process all the data\n",
        "        print(\"---  Validating ---\")\n",
        "      \n",
        "        print('Validation Perplexity: {:8.2f}'.format(run_epoch(model,  data[\"valid\"])))\n",
        "        PlotResult(model)\n",
        "        print(\"----Done! ---\")\n",
        "   \n",
        "    \n",
        "   \n",
        "    \n",
        "# get hyper params with optuna     \n",
        "    \n",
        "\n",
        "# study = optuna.create_study( direction='minimize', pruner=optuna.pruners.MedianPruner(\n",
        "#     n_startup_trials=5, n_warmup_steps=7, interval_steps=1)\n",
        "# )\n",
        "# study.optimize(train, n_trials=70)\n",
        "# plot_optimization_history(study)\n",
        "\n",
        "# print(\"Study statistics: \")\n",
        "# print(\"  Number of finished trials: \", len(study.trials))\n",
        "# print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "# print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "# print(\"Best trial:\")\n",
        "# trial = study.best_trial\n",
        "\n",
        "# print(\"  Value: \", trial.value)\n",
        "\n",
        "# print(\"  Params: \")\n",
        "# for key, value in trial.params.items():\n",
        "#     print(\"    {}: {}\".format(key, value))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to ex2 ! \n",
            "\n",
            "follwing is menu to chose the desired settings for model:\n",
            "\n",
            "press 1 to see dafault settings for all sections\n",
            "\n",
            "press 2 to chose lstm without dropot\n",
            "\n",
            "print 3 to chose lstm with dropout\n",
            "\n",
            "print 4 to chose gru without dropout\n",
            "\n",
            "print 5 to chose gru with dropot\n",
            "\n",
            "print anything else for defualt seeting - lstm without droput \n",
            "Feel free to change the values in args dict  as you wish for custom settings\n",
            "2\n",
            "\n",
            "print 1 to  new model  or 2 for load from default save\n",
            "\n",
            "1\n",
            "{'seq_len': 30, 'batch_size': 20, 'inital_lr': 20, 'num_epochs': 15, 'lr_decay_base': 2, 'ephocs_witout_decay': 4, 'trainRatio': 1, 'data': 'data/', 'hidden_size': 200, 'num_layers': 2, 'dp_keep_prob': 1, 'net': 'lstm', 'load': '', 'save': 'lstm_model.pt', 'log_path': './log_lstm.txt'}\n",
            "------- training ------\n",
            "\n",
            "Train perplexity at epoch 0:   366.18\n",
            "test perplexity at epoch 0:   213.77\n",
            "save model new result :)\n",
            "\n",
            "Train perplexity at epoch 1:   161.93\n",
            "test perplexity at epoch 1:   160.41\n",
            "save model new result :)\n",
            "\n",
            "Train perplexity at epoch 2:   121.10\n",
            "test perplexity at epoch 2:   141.77\n",
            "save model new result :)\n",
            "\n",
            "Train perplexity at epoch 3:   101.01\n",
            "test perplexity at epoch 3:   133.73\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 4:    78.33\n",
            "test perplexity at epoch 4:   120.28\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 5:    65.76\n",
            "test perplexity at epoch 5:   116.32\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 6:    59.35\n",
            "test perplexity at epoch 6:   114.93\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 7:    56.11\n",
            "test perplexity at epoch 7:   114.27\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 8:    54.41\n",
            "test perplexity at epoch 8:   113.73\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 9:    53.49\n",
            "test perplexity at epoch 9:   113.24\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 10:    52.99\n",
            "test perplexity at epoch 10:   112.85\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 11:    52.71\n",
            "test perplexity at epoch 11:   112.59\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 12:    52.56\n",
            "test perplexity at epoch 12:   112.43\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 13:    52.48\n",
            "test perplexity at epoch 13:   112.36\n",
            "save model new result :)\n",
            "\n",
            "decay lr by 2\n",
            "Train perplexity at epoch 14:    52.44\n",
            "test perplexity at epoch 14:   112.32\n",
            "save model new result :)\n",
            "\n",
            "---- end training ------\n",
            "\n",
            "---  Validating ---\n",
            "Validation Perplexity:   116.88\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----Done! ---\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1JNh1vkXR3G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}